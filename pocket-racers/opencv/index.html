<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-pocket-racers/opencv" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.1">
<title data-rh="true">OpenCV | IEEE at UCLA Project Docs</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://projects.ieeebruins.com/pocket-racers/opencv"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="OpenCV | IEEE at UCLA Project Docs"><meta data-rh="true" name="description" content="All instances of referring to a slide number, unless otherwise specified, are referring to the slides from Lecture 2 on Localization."><meta data-rh="true" property="og:description" content="All instances of referring to a slide number, unless otherwise specified, are referring to the slides from Lecture 2 on Localization."><link data-rh="true" rel="icon" href="/img/logo_ieee.svg"><link data-rh="true" rel="canonical" href="https://projects.ieeebruins.com/pocket-racers/opencv"><link data-rh="true" rel="alternate" href="https://projects.ieeebruins.com/pocket-racers/opencv" hreflang="en"><link data-rh="true" rel="alternate" href="https://projects.ieeebruins.com/pocket-racers/opencv" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.f0de6f11.css">
<script src="/assets/js/runtime~main.dd1d4ac2.js" defer="defer"></script>
<script src="/assets/js/main.3701f744.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo_ieee.svg" alt="IEEE Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo_ieee.svg" alt="IEEE Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">IEEE at UCLA Project Docs</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">Docs</a><a href="https://ieeebruins.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">ieeebruins.com<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/">Welcome</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/micromouse/">Micromouse</a><button aria-label="Expand sidebar category &#x27;Micromouse&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/pocket-racers/">Pocket Racers</a><button aria-label="Collapse sidebar category &#x27;Pocket Racers&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pocket-racers/module-0">Module 0</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pocket-racers/module-1">Module 1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pocket-racers/module-2">Module 2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pocket-racers/module-3">Module 3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/pocket-racers/module-4">Module 4</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/pocket-racers/opencv">OpenCV</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/DAV/">DAV</a><button aria-label="Expand sidebar category &#x27;DAV&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/WRAP/">WRAP</a><button aria-label="Expand sidebar category &#x27;WRAP&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/pocket-racers/"><span itemprop="name">Pocket Racers</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">OpenCV</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>OpenCV</h1>
<p>All instances of referring to a slide number, unless otherwise specified, are referring to the slides from Lecture 2 on Localization.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="setting-up-the-camera-on-the-pi">Setting up the camera on the Pi<a href="#setting-up-the-camera-on-the-pi" class="hash-link" aria-label="Direct link to Setting up the camera on the Pi" title="Direct link to Setting up the camera on the Pi">​</a></h2>
<p>All of our Raspberry Pis come with Python 3 preinstalled. You just need to run these commands:</p>
<ul>
<li>
<p><strong>OpenCV</strong>. Install it using Pip by running the following command:</p>
<p>pip3 install opencv-python</p>
</li>
<li>
<p><strong>Numpy</strong>. You’ll most likely_ _need to upgrade your version; this has been an issue on every Pi I tried working with. Run the following command:</p>
<p>pip install -U numpy</p>
</li>
<li>
<p><strong>Some random other stuff</strong>. The first time you do anything with OpenCV on the Pi, you’ll get an error message about a missing file that you’ve probably never heard of before. It’s a simple fix, just run the following command (all on one line):</p>
<p>sudo apt-get install libhdf5-dev libhdf5-serial-dev libatlas-base-dev libjasper-dev</p>
</li>
<li>
<p>If, after running this command (and entering your password when prompted) OpenCV still doesn’t work, visit this <a href="https://stackoverflow.com/questions/53347759/importerror-libcblas-so-3-cannot-open-shared-object-file-no-such-file-or-dire" target="_blank" rel="noopener noreferrer">StackOverflow thread</a>. They mention a bunch of additional libraries you can try to install and see if that fixes things. The thread is a bit old, so you’ll find that a lot of the libraries they mention don’t exist anymore, but some of them should work.</p>
</li>
<li>
<p><strong>Enable the Camera</strong>. Finally, we need to enable the camera on our Pi. Run:</p>
<p>sudo raspi-config</p>
</li>
</ul>
<p><code>	</code>And navigate to Interface Options -&gt; Legacy camera using the arrow keys. Press enter and reboot the Pi.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="downscaling">Downscaling<a href="#downscaling" class="hash-link" aria-label="Direct link to Downscaling" title="Direct link to Downscaling">​</a></h2>
<p>new_dims = (int(img.shape[1] * scaleX), int(img.shape[0] * scaleY))
downscale = cv2.resize(img, new_dims)</p>
<p>Annoyingly, the image <code>shape</code> property (which contains the dimensions of the image array) is encoded as <code>(height, width)</code>, but the resize function makes you supply a tuple in the form of <code>(width, height)</code>. Make sure you get the indices right when multiplying by your scale factors, which should be between 0 and 1.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="color-conversion">Color conversion<a href="#color-conversion" class="hash-link" aria-label="Direct link to Color conversion" title="Direct link to Color conversion">​</a></h2>
<p>new_img = cv2.cvtColor(img, color_code)</p>
<p>Example Color Codes:</p>
<p>color_code = cv2.COLOR_BGR2GRAY
color_code =  cv2.COLOR_BGR2HSV
color_code = cv2.COLOR_BGR2HSV_FULL</p>
<p>For the full list of color codes, see <a href="https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html" target="_blank" rel="noopener noreferrer">this page</a>. There are a <em>lot</em> of color conversion formats here, but for grayscaling you’ll use <code>cv2.COLOR_BGR2GRAY</code> and for HSV you’ll use <code>cv2.COLOR_BGR2HSV</code> or <code>cv2.COLOR_BGR2HSV_FULL</code>. Note that OpenCV encodes your images by default as BGR (blue-green-red) and not RGB, so you have to use the appropriate conversions.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="box-blur">Box Blur<a href="#box-blur" class="hash-link" aria-label="Direct link to Box Blur" title="Direct link to Box Blur">​</a></h2>
<code><em>blur = cv2.blur(img,(n,m))</em></code>
<p><code>(n,m)</code> is the size of your blurring kernel. For example, <code>(3, 3)</code> would indicate that each pixel is getting replaced with the average of the 3x3 box around it – a small amount of blurring. Something like <code>(13, 13)</code>, on the other hand, would blur each pixel with a 13x13 box of pixels around it, which is much more significant. However, they don’t have to be equal – if you really wanted to, you could do a rectangular blurring kernel. Try things and see what they do!</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="gaussian-blur">Gaussian Blur<a href="#gaussian-blur" class="hash-link" aria-label="Direct link to Gaussian Blur" title="Direct link to Gaussian Blur">​</a></h2>
<code>blur = cv2.GaussianBlur(img,ksize=(k,k),sigmaX=0)</code>
<p>Here, ksize is the side length of our kernel (must be odd). Sigma X is the standard deviation in the X direction and if set to 0 is automatically calculated from ksize (sigmaY defaults to the same as sigmaX) For more details, visit <a href="https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1" target="_blank" rel="noopener noreferrer">this page</a>. For the functional difference between box blurring and Gaussian blurring, see slide 23.</p>
<p>For additional blurring techniques, visit <a href="https://docs.opencv.org/4.x/d4/d13/tutorial_py_filtering.html" target="_blank" rel="noopener noreferrer">this page</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="simple-thresholding">Simple thresholding<a href="#simple-thresholding" class="hash-link" aria-label="Direct link to Simple thresholding" title="Direct link to Simple thresholding">​</a></h2>
<p>_, new_img = cv2.threshold(src, thresh, maxval, type)
type = cv2.THRESH_BINARY_INV or cv2.THRESH_BINARY</p>
<p>This is done on a grayscale image. When the thresholding type is set to <code>cv2.THRESH_BINARY</code>, it sets all pixels above <code>thresh</code> to <code>maxval</code> and all pixels below it to 0. When it’s set to <code>cv2.THRESH_BINARY_INV</code>, the function sets all pixels above <code>thresh</code> to 0 and all pixels below it to 255.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="adaptive-thresholding">Adaptive thresholding<a href="#adaptive-thresholding" class="hash-link" aria-label="Direct link to Adaptive thresholding" title="Direct link to Adaptive thresholding">​</a></h2>
<p>mask = cv2.adaptiveThreshold(im, maxValue=255,
adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C, thresholdType=cv2.THRESH_BINARY_INV, blockSize=k, C=t)</p>
<p>This function implements adaptive thresholding; the values you will be playing with should be <code>blockSize</code> and <code>C</code> (maybe also the adaptive method). C is a constant that is <strong>subtracted</strong> from the adaptive threshold.</p>
<p>For all the different types of thresholding in OpenCV, visit <a href="https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html" target="_blank" rel="noopener noreferrer">this page</a>.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>There’s been some confusion about how the C value works exactly. Basically, the adaptive thresholding function operates on every pixel in the original image as follows:</p><ol>
<li>Calculate a threshold by taking the Gaussian mean of the values in a <code>k</code>-by-<code>k</code> block centered on the pixel in question.</li>
<li>Subtract this value by C.</li>
<li>Compare the resulting threshold value with the value of the pixel and act in accordance with <code>thresholdType</code>.</li>
</ol></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="thresholding-with-hsv">Thresholding with HSV<a href="#thresholding-with-hsv" class="hash-link" aria-label="Direct link to Thresholding with HSV" title="Direct link to Thresholding with HSV">​</a></h2>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>The range of hues in OpenCV is <strong>0 to 180</strong>, not 0 to 255. Using values above 180, to the best of our knowledge, don’t really do anything.</p></div></div>
<code><em>mask = cv2.inRange(hsv, lowerBound, upperBound)</em></code>
<p>The traditional threshold functions don’t really work for HSV images, so we use the <code>cv2.inRange()</code> function instead. Here, lowerBound and upperBound are three-tuples. A range of, for example,</p>
<p>cv2.inRange(hsv, (135, 0, 0), (180, 255, 255))</p>
<p>would create a mask preserving only those pixels that fall between the hue range of 135-180; in other words, purple to red. Since the saturation and value ranges are 0-255, pixels of any saturation and value will be preserved in the mask. When you display a mask using <code>cv2.imshow()</code>, it’ll give you an image that’s white at all the pixels that meet the range criteria and black everywhere else. Refer to slide 38 in the lecture for an example.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bitwise-mask-operations">Bitwise mask operations<a href="#bitwise-mask-operations" class="hash-link" aria-label="Direct link to Bitwise mask operations" title="Direct link to Bitwise mask operations">​</a></h2>
<code><em>mask = np.bitwise_and(x1, x2) <br>
<!-- -->mask = np.bitwise_or(x1, x2)</em></code>
<p>mask = np.bitwise_not(x1, x2)
result = cv2.bitwise_and(x1, x1, mask=x2)</p>
<p>These work about as you’d expect them to, except instead of operating on two bits they operate on two arrays of bits. See slide 39 for a visual explanation of their functions.</p>
<p>You’ll note that the syntax for the operation combining a mask with an image is slightly different from the operations on just masks themselves. This is because in Python and OpenCV, your image will typically be represented as an array of 3 “channels”, for R-G-B or H-S-V. However, you can’t combine a 3-channel image with a 1-channel mask (because it’s just black and white) using Numpy, so you have to use the OpenCV function instead.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="erosion-and-dilation">Erosion and Dilation<a href="#erosion-and-dilation" class="hash-link" aria-label="Direct link to Erosion and Dilation" title="Direct link to Erosion and Dilation">​</a></h2>
<p>res = cv2.erode(img, np.ones((k,k), np.uint8), iterations=n)
res = cv2.dilate(img, np.ones((k,k), np.uint8), iterations=n)</p>
<p>Like with previous functions, <code>(k,k)</code> is the block size. <code>n</code> is a whole number representing the number of times you want your erosion or dilation to be applied to the image.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="floodfill">Floodfill<a href="#floodfill" class="hash-link" aria-label="Direct link to Floodfill" title="Direct link to Floodfill">​</a></h2>
<p>h, w = img.shape[:2]
mask = np.zeros((h + 2, w + 2), np.uint8)
cv2.floodFill(img, mask, (j, k), color)</p>
<p>Floodfill is an algorithm that essentially starts at a certain point and “spreads out” to all the adjacent points in the image that are equal to it. You can think of it as doing the exact same thing that the Fill Bucket tool does in computer drawing programs.</p>
<p>Here, the floodfill function modifies the <code>img</code> parameter directly – in other words, it <strong>does not return a new image.</strong> The <code>mask</code> parameter will in almost all cases be a slightly bigger but empty image; in practice, nonzero values in the mask specify “walls” that the floodfill algorithm can’t cross. Finally, <code>(j,k)</code> is the starting point (the function will fill whatever <em>closed</em> region contains that point) and <code>color</code> is the color value (from 0-255) that you want to fill the region with.</p>
<p>Note that in the starting point <code>(j,k)</code>, <code>j</code> represents the column and <code>k</code> represents the row – like an XY-coordinate pair starting at the top left of the image and growing downwards.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="simple-blob-detection">Simple Blob Detection<a href="#simple-blob-detection" class="hash-link" aria-label="Direct link to Simple Blob Detection" title="Direct link to Simple Blob Detection">​</a></h2>
<p>bdp = cv2.SimpleBlobDetector_Params()
bdp.filterByArea = False
bdp.filterByConvexity = False
bdp.filterByCircularity = True
bdp.filterByInertia = False
bdp.filterByColor = True
bdp.blobColor = 255
bdp.minCircularity = 0.5
bdp.maxCircularity = 1
detector = cv2.SimpleBlobDetector_create(bdp)
points = detector.detect(mask)</p>
<p>The above code extracts all white blobs with a circularity greater than 0.5. You can read more about the different features <a href="https://docs.opencv.org/3.4/d0/d7a/classcv_1_1SimpleBlobDetector.html" target="_blank" rel="noopener noreferrer">here</a>.</p>
<p>The list of all available parameters for the blob detector can be found <a href="https://docs.opencv.org/3.4/d8/da7/structcv_1_1SimpleBlobDetector_1_1Params.html" target="_blank" rel="noopener noreferrer">here</a> (and the ones we use are listed below). To add one of the above filters, set it to <code>True</code> instead of <code>False</code> as shown above, and then update the relevant minimum and maximum parameters. The documentation is for C++, but the names should be the same (and they’re listed below); and if a certain parameter doesn’t work, a little Googling goes a long way :-)</p>
<p>So far, we’ve used the following <code>SimpleBlobDetector_Params<em></em></code> members:</p>
<ul>
<li><code>bool 	filterByArea</code></li>
<li><code>float 	minArea</code></li>
<li><code>float 	maxArea </code></li>
<li><code>bool 	filterByCircularity</code></li>
<li><code>float 	minCircularity</code></li>
<li><code>float 	maxCircularity</code></li>
<li><code>bool 	filterByInertia</code></li>
<li><code>float 	minInertiaRatio</code></li>
<li><code>float 	maxInertiaRatio</code></li>
<li><code>bool 	filterByColor</code></li>
<li><code>int		blobColor</code></li>
<li><code>bool 	filterByConvexity</code></li>
<li><code>float 	minConvexity</code></li>
<li><code>float 	maxConvexity</code></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="finding-contours">Finding contours<a href="#finding-contours" class="hash-link" aria-label="Direct link to Finding contours" title="Direct link to Finding contours">​</a></h2>
<p>contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</p>
<p><code>contours</code> is a list of all the contours in the image.</p>
<p><code>hierarchy</code> is a 2D array containing hierarchical information about each contour. In the following diagram, <code><em>i</em></code> is the index of a given contour in the list <code>contours</code>. <code>hierarchy</code> is actually an array containing the tree of contours, so the data we’re actually concerned with is in <code>hierarchy[0]</code>. The <code>i</code>-th element in the tree is an array of 4 elements: the next sibling, previous sibling, first child, and parent, respectively. If any of these elements don’t exist (for example, the parent of the root contour or any node with no siblings), it’ll be <code>-1</code> in the array.</p>
<p><img loading="lazy" alt="drawing" src="/assets/images/image7-42e526ad0b1b2d3fc2a1cd7f1c829524.png" width="1088" height="908" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="contour-area">Contour area<a href="#contour-area" class="hash-link" aria-label="Direct link to Contour area" title="Direct link to Contour area">​</a></h2>
<p>area = cv2.contourArea(contours[i])</p>
<p>This function returns the area of the contour, in pixels. <code>contours[i]</code>, of course, is the <em>i</em>-th contour in the list of contours.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="contour-convex-hull">Contour convex hull<a href="#contour-convex-hull" class="hash-link" aria-label="Direct link to Contour convex hull" title="Direct link to Contour convex hull">​</a></h2>
<p>hull = cv2.convexHull(contours[i])</p>
<p>Remember that the convex hull of a blob is a purely convex polygon that encloses a contour. To find the convexity of a contour, you calculate the ratio of the area of the contour to the area of its convex hull.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="contour-bounding-rectangle">Contour bounding rectangle<a href="#contour-bounding-rectangle" class="hash-link" aria-label="Direct link to Contour bounding rectangle" title="Direct link to Contour bounding rectangle">​</a></h2>
<p>x,y,w,h = cv2.boundingRect(contours[i])</p>
<p>The regularly-oriented bounding rectangle of a contour isn’t as “tightly wrapped” as the convex hull, so to speak. Typically the formula for calculating a bounding rectangle involves finding the leftmost and rightmost x-coordinates in the blob, finding the topmost and bottommost y-coordinates, and creating a rectangle using those coordinates to determine:</p>
<p><code>x</code> – the <em>x</em>-coordinate of the top-left corner of the rectangle</p>
<p><code>y</code> – the <em>y</em>-coordinate of the top-left corner of the rectangle</p>
<p><code>w</code> – the width of the rectangle</p>
<p><code>h</code> – the height of the rectangle</p>
<p>This will typically result in the bounding rectangle having more excess area than the convex hull of a given contour.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="contour-moment-of-inertia">Contour moment of inertia<a href="#contour-moment-of-inertia" class="hash-link" aria-label="Direct link to Contour moment of inertia" title="Direct link to Contour moment of inertia">​</a></h2>
<p>moments = cv2.moments(contours[i])
mx = int(moments[&quot;m10&quot;] / moments[&quot;m00&quot;])
my = int(moments[&quot;m01&quot;] / moments[&quot;m00&quot;])</p>
<p>The <code>cv2.moments</code> function actually returns some more complicated data than what we’ll have to use, but these are the formulas for calculating our needed coordinates. <code>mx</code> and <code>my</code> are the x and y-coordinates of the moment of inertia of the contour at <code>contours[i]</code>.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Sometimes, you’ll get a DivideByZero error from either of these lines in your code. The issue here is that, if your contours don’t separate properly, the value <code>moments[&quot;m00&quot;]</code> will be zero and your division will cause an error. To fix this, you can simply wrap these calculations in a <code>try/except</code> block, handling the error as you see fit.</p></div></div>
<p>The guide <a href="https://docs.opencv.org/3.4/dd/d49/tutorial_py_contour_features.html" target="_blank" rel="noopener noreferrer">here</a> has additional functions that you can use with contours. As we use more, we’ll add them to these docs.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/UCLA-IEEE/projects.ieeebruins.com/tree/main/docs/pocket-racers/opencv.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/pocket-racers/module-4"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Module 4</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/DAV/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">DAV</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#setting-up-the-camera-on-the-pi" class="table-of-contents__link toc-highlight">Setting up the camera on the Pi</a></li><li><a href="#downscaling" class="table-of-contents__link toc-highlight">Downscaling</a></li><li><a href="#color-conversion" class="table-of-contents__link toc-highlight">Color conversion</a></li><li><a href="#box-blur" class="table-of-contents__link toc-highlight">Box Blur</a></li><li><a href="#gaussian-blur" class="table-of-contents__link toc-highlight">Gaussian Blur</a></li><li><a href="#simple-thresholding" class="table-of-contents__link toc-highlight">Simple thresholding</a></li><li><a href="#adaptive-thresholding" class="table-of-contents__link toc-highlight">Adaptive thresholding</a></li><li><a href="#thresholding-with-hsv" class="table-of-contents__link toc-highlight">Thresholding with HSV</a></li><li><a href="#bitwise-mask-operations" class="table-of-contents__link toc-highlight">Bitwise mask operations</a></li><li><a href="#erosion-and-dilation" class="table-of-contents__link toc-highlight">Erosion and Dilation</a></li><li><a href="#floodfill" class="table-of-contents__link toc-highlight">Floodfill</a></li><li><a href="#simple-blob-detection" class="table-of-contents__link toc-highlight">Simple Blob Detection</a></li><li><a href="#finding-contours" class="table-of-contents__link toc-highlight">Finding contours</a></li><li><a href="#contour-area" class="table-of-contents__link toc-highlight">Contour area</a></li><li><a href="#contour-convex-hull" class="table-of-contents__link toc-highlight">Contour convex hull</a></li><li><a href="#contour-bounding-rectangle" class="table-of-contents__link toc-highlight">Contour bounding rectangle</a></li><li><a href="#contour-moment-of-inertia" class="table-of-contents__link toc-highlight">Contour moment of inertia</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">More of us!</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/RREtsea" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://instagram.com/uclaieee" target="_blank" rel="noopener noreferrer" class="footer__link-item">Instagram<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">© 2025 IEEE at UCLA. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>